[[installation-proxy-containers-k3s]]
= Install Containerized {productname} Proxy on [literal]``k3s``

[[installation-proxy-containers-k3s-k3s]]
== Installing k3s

On the container host machine, install [literal]``k3s`` without the load balancer and traefik router (replace [literal]``<K3S_HOST_FQDN>`` with the FQDN of your k3s host):

----
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="--disable=traefik --disable=servicelb --tls-san=<K3S_HOST_FQDN>" sh -
----

[[installation-proxy-containers-k3s-cluster-access]]
== Configuring cluster access

[literal]``helm`` needs a configuration file to connect to the target kubernetes cluster.

On the cluster server machine run the following command to create the [path]``kubeconfig-k3s.yaml`` configuration file.
The [path]``kubeconfig-k3s.yaml`` file can be optionally transferred to a work machine:

----
kubectl config view --flatten=true | sed 's/127.0.0.1/<K3S_HOST_FQDN>/' >kubeconfig-k3s.yaml
----

Before calling [literal]``helm``, run:

----
export KUBECONFIG=/path/to/kubeconfig-k3s.yaml
----

[[installation-proxy-containers-k3s-helm]]
== Installing helm

[NOTE]
====
The Containers Module is required to install [literal]``helm``.
====

To install it run:

----
zypper in helm
----

[[installation-proxy-containers-k3s-metallb]]
== Installing [literal]``metalLB``

[literal]``MetalLB`` is the load balancer that will expose the {productname} proxy pod services to the outside world.
To install it, run:

----
helm repo add metallb https://metallb.github.io/metallb
helm install --create-namespace -n metallb metallb metallb/metallb 
----

[literal]``MetalLB`` still requires a configuration to know the virtual IP address range to be used.
In this example, the virtual IP addresses will be from [literal]``192.168.122.240`` to [literal]``192.168.122.250``, but that range could be lowered to a single address if the host only exposes the {productname} proxy.
These addresses need to be a subset of the server network.

Create a [path]``metallb-config.yaml`` configuration file with the following settings and an IP address range that aligns with the deployed network:

----
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: l2-pool
  namespace: metallb
spec:
  addresses:
  - 192.168.122.240-192.168.122.250
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: l2 
  namespace: metallb
spec:
  ipAddressPools:
  - l2-pool
----

Apply this configuration by running:

----
kubectl apply -f metallb-config.yaml
----


[[installation-proxy-containers-k3s-deploy]]
== Deploying the {productname} proxy helm chart

Create a configuration file forcing the IP address that [literal]``MetalLB`` will use for the {productname} Proxy services.
This IP address needs to be the one to which the proxy FQDN entered when creating the proxy configuration.
It also needs to be resolvable from both the {productname} Server and the client systems to connect to the proxy.

This example will use [literal]``192.168.122.241``.

Create a [path]``custom-values.yaml`` file with the following content.
If the [literal]``MetalLB`` IP address range only contains a single address, the last line can be removed.

----
services:
  annotations:
    metallb.universe.tf/allow-shared-ip: key-to-share-ip
    metallb.universe.tf/loadBalancerIPs: 192.168.122.241
----


[NOTE]
====
The parameter [literal]``metallb.universe.tf/allow-shared-ip`` does not need changing.

You need to adjust the parameter [literal]``metallb.universe.tf/loadBalancerIPs`` to your network setup.
====


To configure the storage of the volumes to be used by the {productname} Proxy pod, define persistent volumes for the following claims.
If you do not customize the storage configuration, k3s will automatically create the storage volumes for you.

The persistent volume claims are named:

* [literal]``squid-cache-pv-claim``
* [literal]``/package-cache-pv-claim``
* [literal]``/tftp-boot-pv-claim``

Create the configuration for the {productname} Proxy as documented in xref:proxy-container-setup.adoc[].
Copy and extract the configuration [literal]``tar.gz`` file and then deploy the helm chart:

ifeval::[{uyuni-content} == true]
----
tar xf /path/to/config.tar.gz
helm install uyuni-proxy oci://registry.opensuse.org/uyuni/proxy -f config.yaml -f httpd.yaml -f ssh.yaml -f custom-values.yaml
----
endif::[]

ifeval::[{suma-content} == true]
----
tar xf /path/to/config.tar.gz
helm install uyuni-proxy oci://registry.suse.com/suse/manager/4.3/proxy -f config.yaml -f httpd.yaml -f ssh.yaml -f custom-values.yaml
----
endif::[]


For more information see https://kubernetes.io/docs/concepts/storage/persistent-volumes/ (kubernetes) or https://rancher.com/docs/k3s/latest/en/storage/ (k3s) documentation.
