[[advanced.topics.proxy.quickstart]]
= {productname} {productnumber} Proxy
:linkattrs:
// SUSE ENTITIES FOR GITHUB
// System Architecture
:zseries: z Systems
:ppc: POWER
:ppc64le: ppc64le
:ipf : Itanium
:x86: x86
:x86_64: x86_64
// Rhel Entities
:rhel: Red Hat Enterprise Linux
:rhnminrelease6: Red Hat Enterprise Linux Server 6
:rhnminrelease7: Red Hat Enterprise Linux Server 7
// SUSE Manager Entities
:productname: Uyuni
:susemgr: SUSE Manager
:susemgrproxy: SUSE Manager Proxy
:productnumber: 3.2
:saltversion: 2018.3.0
:webui: WebUI
// SUSE Product Entities
:sles-version: 12
:sp-version: SP3
:jeos: JeOS
:scc: SUSE Customer Center
:sls: SUSE Linux Enterprise Server
:sle: SUSE Linux Enterprise
:slsa: SLES
:suse: SUSE
:ay: AutoYaST
// Asciidoctor Front Matter
:doctype: book
:sectlinks:

:icons: font
:experimental:
:sourcedir: .
:imagesdir: images

[abstract]
--
This chapter explains how to install and set up {productname} {productnumber} Proxy.
It also provides notes about migrating a previous proxy such as version 2.1, 3.0, or 3.1 to version 3.2.
--



[[at.manager.proxy.concepts]]
== Overview

{productname} {productnumber} Proxy is a {productname} add-on that caches software packages on an internal, central server.
The proxy caches patch updates from {suse} or custom RPMs generated by third-party organizations.
A proxy allows you to use bandwidth more effectively because client systems connect to the proxy for updates, and the {productname} server is no longer required to handle all client requests.
The proxy also supports transparent custom package deployment.

{productname} Proxy is an open source (GPLv2) solution that provides the following features:

* Cache software packages within a Squid proxy.
* Client systems see the {susemgrproxy} as a {productname} server instance.
* The {susemgrproxy} is registered as a client system with the {productname} server.

The primary goal of a {susemgrproxy} is to improve {productname} performance by reducing bandwidth requirements and accelerating response time.



[[at.manager.proxy.inst-and-clients]]
== Proxy Installation and Connecting Clients



[[at.manager.proxy.requirements]]
=== Requirements

The following section provides {susemgrproxy} requirements.

.Supported Client Systems
For supported clients and their requirements, see Supported Client Systems.

.Hardware Requirements
Hardware requirements highly depend on your usage scenario.
When planning proxy environments, consider the amount of data you want to cache on your proxy.
If your proxy should be a 1:1 mirror of your {productname}, the same amount of disk space is required.
For specific hardware requirements, see the following table.

[cols="1,1", options="header"]
|===
| Hardware | Required
| CPU             | Multi-core 64-bit CPU (x86_64).
| RAM             | Minimum 4{nbsp} GB for a non-production server
|                 | Minimum 16{nbsp} GB for a production server
| Free Disk Space | Minimum 100{nbsp} GB for base installation and at least 50 GB for caching per SUSE product and +100 GB per Red Hat product; a resizeable partition strongly recommended.
|===

[TIP]
.Storage for Proxy Data
====
{suse} recommends storing the squid proxy caching data on a separate disk formatted with the XFS file system.
====

.SSL Certificate Password
For installing the proxy, you need the SSL certificate password entered during the initial installation of {productname}.

.Network Requirements
For additional network requirements, see Additional Requirements.

.{scc}
For using {susemgrproxy}, you need an account at {scc} (SCC) where your purchased products and product subscriptions are registered.
Make sure you have the following subscriptions:

* One or more subscriptions for {susemgrproxy} .
* One or more subscriptions for {productname} .
* Subscriptions for the products on the client systems you want to register with {productname} via {susemgrproxy} .
* Subscriptions to client entitlements for the client system you want to register with {productname} via {susemgrproxy} .

.Network Time Protocol (NTP)
The connection to the Web server via Secure Sockets Layer (SSL) requires correct time settings on the server, proxy and clients.
For this reason, all systems must use NTP.
For more information, see https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_netz_xntp.html.

.Virtual Environments
The following virtual environments are supported:

* http://www.linux-kvm.org/page/Main_Page
* http://www.vmware.com/
* http://www.microsoft.com/en-us/server-cloud/solutions/virtualization.aspx

For running {susemgrproxy}
in virtual environments, use the following settings for the virtual machine (VM):

* At least 1 GB of RAM
* Bridged network



[[at.manager.proxy.inst]]
=== Installation and Setup

The following section will guide you through the installation and setup procedure.

[IMPORTANT]
.Registering Proxies
====
{productname} Proxy systems are registered as traditional clients using a bootstrap script.
Currently there is no method to register proxy systems using Salt.
A {susemgrproxy} can serve both Traditional and Salt clients.
====



[[at.manager.proxy.install.prep]]
.Procedure: Registering the Proxy

[IMPORTANT]
====
First completely download the channels ({sle} 12 SP3) and then create the activation key.
Only then you can select the correct child channels.
====
+

. Create an activation key based on the {sle} 12 SP3 base channel.
For more information about activation keys, see <<create.act.keys>>.
+

.Proxy Activation Key

image::proxy-key.png[]
. Click the menu:Child Channels[] subtab and select the {productname} {productnumber} Proxy child channel with the matching update channel ([systemitem]``SUSE Manager Proxy-3.2-Pool`` and [systemitem]``SUSE-Manager-Proxy-3.2-Updates`` ).
These child channels are required for providing the proxy packages and updates.
As for normal SLES clients, [systemitem]``SLES12-SP3-Updates`` plus [systemitem]``SLE-Manager-Tools12-Pool`` and [systemitem]``SLE-Manager-Tools12-Updates`` are required.
+

.Base and Child Proxy Channel

image::sles12-proxy-child.png[]



[[at.manager.proxy.install.prep.bss]]
. Modify a bootstrap script for the proxy.
Ensure unchecking menu:Bootstrap using Salt[] , because in this case the proxy must be bootstrapped as a so-called traditional client.
For more information about bootstrap scripts, see <<modify.bootstrap.script>>.

. Bootstrap the client with the bootstrap script.
. You will see a list of channels to which your client is already subscribed to.
Select the two unchecked proxy channels which include the [systemitem]``SUSE Manager Proxy-3.2-Pool`` and [systemitem]``SUSE-Manager-Proxy-3.2-Updates`` , then select menu:Change Subscriptions[] to continue.
This will provide the required repositories for the proxy packages from the {productname} server to the client.

A few more steps are still needed:

* install the [path]``suma_proxy`` pattern (see <<at.manager.proxy.run.pattern>>);
* copy the SSL certificate and key from the server (see <<at.manager.proxy.run.copycert>>);
* run [command]``configure-proxy.sh`` (see <<at.manager.proxy.run.confproxy>>);

You will then be able to register your clients against the proxy using the {webui} or a bootstrap script as if it were a {productname} server.
For more information, see <<at.manager.proxy.register.saltclients>>.



[[at.manager.proxy.run.pattern]]
=== Install the [path]``suma_proxy`` pattern

Make sure the [path]``suma_proxy`` pattern version 2.5.1.3 or later is installed using the following command on the proxy as root:

----
zypper in -t pattern suma_proxy
----

The new salt-broker service will be automatically started at the end of the package installation.
This service forwards the Salt interactions to the {productname} server.

[NOTE]
.Proxy Chains
====
It is possible to arrange Salt proxies in a chain.
In such a case, the upstream proxy is named "`parent`".
====

Make sure the proxie's TCP ports `4505` and `4506` are open and that the proxy can reach the {productname} server (or another upstream proxy) on these ports.



[[at.manager.proxy.run.copycert]]
=== Copy Server Certificate and Key

The proxy will share some SSL information with the {productname} server, so the next step is to copy the certificate and its key from the {productname} server or the upstream proxy.

As root, enter the following commands on the proxy using your {productname} server or chained proxy named as [replaceable]``PARENT``:

----
cd /root/ssl-build scp root@`PARENT`:/root/ssl-build/RHN-ORG-PRIVATE-SSL-KEY scp root@`PARENT`:/root/ssl-build/RHN-ORG-TRUSTED-SSL-CERT scp root@`PARENT`:/root/ssl-build/rhn-ca-openssl.cnf .
----


[NOTE]
.Known Limitation
====
The {susemgrproxy} functionality is only supported if the SSL certificate was signed by the same CA as the {productname} Server certificate.
Using certificates signed by different CAs for Proxies and Server is not supported.
====



[[at.manager.proxy.run.confproxy]]
=== Running [command]``configure-proxy.sh``

The [command]``configure-proxy.sh`` script will finalize the setup of your {susemgrproxy}.

Now execute the interactive [command]``configure-proxy.sh`` script.
Pressing kbd:[Enter] without further input will make the script use the default values provided between brackets ``[]``.
Here is some information about the requested settings:

{productname} Parent::
A {productname} parent can be either another proxy server or a {productname} server.

HTTP Proxy::
A HTTP proxy enables your {productname} proxy to access the Web.
This is needed if where direct access to the Web is prohibited by a firewall.

Proxy Version to Activate::
Normally, the correct value (3.0, 3.1, or 3.2) should be offered as a default.

Traceback Email::
An email address where to report problems.

Use SSL::
For safety reasons, press ``Y``.

Do You Want to Import Existing Certificates?::
Answer ``N``.
This ensures using the new certificates that were copied previously from the {productname} server.

Organization::
The next questions are about the characteristics to use for the SSL certificate of the proxy.
The organization might be the same organization that was used on the server, unless of course your proxy is not in the same organization as your main server.

Organization Unit::
The default value here is the proxy's hostname.

City::
Further information attached to the proxy's certificate.
Beware the country code must be made of two upper case letters.
For further information on country codes, refer to the online https://www.iso.org/obp/ui/#search[list of alpha-2 codes].
+

[TIP]
.Country Code
====
As the country code enter the country code set during the SUSE Manager installation.
For example, if your proxy is in US and your {productname} in DE, you must enter `DE` for the proxy.
====
+

Cname Aliases (Separated by Space)::
Use this if your proxy server can be accessed through various DNS CNAME aliases.
Otherwise it can be left empty.

CA Password::
Enter the password that was used for the certificate of your {productname} server.

Do You Want to Use an Existing SSH Key for Proxying SSH-Push Salt Minions?::
Use this option if you want to reuse a SSH key that was used for SSH-Push Salt minions on the server.

Create and Populate Configuration Channel rhn_proxy_config_1000010001?::
Accept default ``Y``.

SUSE Manager Username::
Use same user name and password as on the {productname} server.

Activate advertising proxy via SLP?::
SLP stands for Service Location Protocol.

If parts are missing, such as CA key and public certificate, the script prints commands that you must execute to integrate the needed files.
When the mandatory files are copied, re-run [command]``configure-proxy.sh``.
Also restart the script if a HTTP error was met during script execution.

[command]``configure-proxy.sh`` activates services required by {productname} Proxy, such as [systemitem]``squid``, [systemitem]``apache2``, [systemitem]``salt-broker``, and [systemitem]``jabberd``.

To check the status of the proxy system and its clients, click the proxy system's details page on the {webui} (menu:Systems[Proxy], then the system name). menu:Connection[] and menu:Proxy[] subtabs display the respective status information.



[[at.manager.proxy.register.saltclients]]
=== Registering Salt Clients via {susemgrproxy}

Proxy servers may now act as a broker and package cache for Salt minions.
These minions can be registered with a bootstrap script like the traditional clients, or directly from the {webui} or the command line.

Registering Salt clients via {susemgrproxy} from the {webui}
is done almost the same way as registering clients directly with the {productname} server.
The difference is that you specify the name of the proxy in the menu:Proxy[] drop-box on menu:Salt[Bootstrapping] page.

.Bootstrapping a Salt Client With a Proxy
image::proxy-saltbootstrap.png[scaledwidth=80%]

.Procedure: Register a Salt client through a proxy from command line
. Instead of the {webui} , you may use the command line to register a minion through a proxy.
To do so, add the proxy FQDN as the master in the minions configuration file located at:
+

----
/etc/salt/minion
----
+

or alternatively:
+

----
/etc/salt/minion.d/`name`.conf
----

. Add the FQDN to the minion file:
+

----
master: proxy123.example.com
----
+

Save and restart the salt-minion service with:
+

----
systemctl restart salt-minion
----

. On the proxy, accept the new minion key with:
+

----
salt-key -a 'minion'
----
+

The minion will now connect to the proxy exclusively for Salt operations and normal HTTP package downloads.



[[at.manager.proxy.register.clients]]
=== Registering Clients via {susemgrproxy} with a Script

Registering clients (either traditional or Salt) via {susemgrproxy} with a script is done almost the same way as registering clients directly with the {productname} server.
The difference is that you create the bootstrap script on the {susemgrproxy} with a command-line tool.
The bootstrap script then deploys all necessary information to the clients.
The bootstrap script refers some parameters (such as activation keys or GPG keys) that depend on your specific setup.


. Create a client activation key on the {productname} server using the {webui}.
See <<create.act.keys>>.
. On the proxy, execute the [command]``mgr-bootstrap`` command-line tool as {rootuser}.
If needed, use the additional command-line switches to tune your bootstrap script. An important option is [command]``--traditional`` that enables to opt for a traditional client instead of a salt minion.
+
To view available options type [command]``mgr-bootstrap --help`` from the command line:
+

----
# ``mgr-bootstrap --activation-keys=key-string``
----

. Optionally edit the resulting bootstrap script.
Execute the bootstrap script on the clients as described in <<connect.first.client>>.


The clients are registered with the {susemgrproxy} specified in the bootstrap script.



[[at.additional.info.about.client.registration.on.proxies]]
=== Additional Information about Client Registration on Proxies

Within the {webui}, standard proxy pages will show information about client, no matter whether minions or traditional clients.

A list of clients connected to a proxy can be located under menu:Systems[] <proxy name> menu:Details[]menu:Proxy[].

A list of chained proxies for a minion can be located under menu:Systems[] <minion name> menu:Details[]menu:Connection[]

If you decide to move any of your clients between proxies or the server you will need to repeat the registration process from scratch.



[[advanced.topics.proxy.pxe]]
== Enabling PXE Boot via {susemgrproxy}



[[advanced.topics.proxy.pxe.sync]]
=== Synchronizing Profiles and System Information

To enable PXE boot via a proxy server, additional software must be installed and configured on both the {productname} server and the {susemgrproxy} server.

. On the {productname} server install [package]#susemanager-tftpsync# :
+

----
zypper in susemanager-tftpsync
----

. On the {susemgrproxy} server install [package]#susemanager-tftpsync-recv# :
+

----
zypper in susemanager-tftpsync-recv
----

. Run the [command]``configure-tftpsync.sh`` setup script and enter the requested information:
+

----
configure-tftpsync.sh
----
+

It asks for hostname and IP address of the {productname} server and of the proxy itself.
Additionally, it asks for the tftpboot directory on the proxy.

. On the {productname} server, run [command]``configure-tftpsync.sh`` to configure the upload to the {susemgrproxy} server:
+

----
configure-tftpsync.sh FQDN_of_Proxy_Server
----

. To initiate an initial synchronization on the SUSE Manager Server run:
+

----
cobbler sync
----
+

Also can also be done after each a change within Cobbler that needs to be synchronized immediately.
Otherwise Cobbler synchronization will also run automatically when needed.
For more information about Cobbler, see <<advanced.topics.cobbler>>.



[[advanced.topics.proxy.pxe.dhcp]]
=== Configuring DHCP for PXE via {susemgrproxy}

{productname} is using Cobbler to provide provisioning.
PXE (tftp) is installed and activated by default.
To enable systems to find the PXE boot on the {susemgrproxy} server add the following to the DHCP configuration for the zone containing the systems to be provisioned:

----
next-server:`IP_Address_of_SUSE_Manager_Proxy_Server`filename: "pxelinux.0"
----



[[advanced.topics.proxy.migration3]]
== Migrating {productname} 3 Proxy to Version 3.1

The recommended order for migrations is to first migrate the server and then the proxies.
Note that a {productname} 3 Proxy works correctly with {productname} 3.1.

For the migration of the proxies there are two possible approaches:

* Existing {productname} proxies may be upgraded to version 3.1 with {yast} or [command]``zypper`` migration.
* Alternatively, the proxies may be replaced by new ones.

This section documents both approaches.


[[at.replacing.a.susemgrproxy]]
=== Replacing a {susemgrproxy}

A {susemgrproxy} is `dumb` in the sense that it does not contain any information about the clients which are connected to it.
A {susemgrproxy} can therefore be replaced by a new one.
Naturally, the replacement proxy must have the same name and IP address as its predecessor.

In order to replace a {susemgrproxy} and keeping the clients registered to the proxy leave the old proxy in {productname}.
Create a reactivation key for this system and then register the new proxy using the reactivation key.
If you do not use the reactivation key, you will need to re-registered all the clients against the new proxy.

[[proc.advanced.topics.proxy.migration3.replace]]
.Procedure: Replacing a {susemgrproxy}and Keeping the ClientsRegistered
. Before starting the actual migration procedure, save the data from the old proxy, if needed.
Consider copying important data to a central place that can also be accessed by the new server:
** Copy the scripts that are still needed.
** Copy the activation keys from the previous server.
Of course, it is always better to re-create the keys.
. Shutdown the server.
. Install a new {productname} 3.1 Proxy, see <<at.manager.proxy.inst-and-clients>>.
. In the SUSE Manager {webui} select the newly installed {susemgrproxy} and delete it from the systems list.
[[step.at.proxy.migration3.replace.react]]
. In the {webui} , create a reactivation key for the old proxy system: On the System Details of the old proxy click menu:Reactivation[].
Then click menu:Generate New Key[] , and remember it (write it on a piece of paper or copy it to the clipboard).
For more information about reactivation keys, see <<s5-sm-system-details-react>>.
. After the installation of the new proxy, perform the following actions (if needed):
** Copy the centrally saved data to the new proxy system.
** Install any other needed software.
** If the proxy is also used for autoinstallation, do not forget to setup TFTP synchronization.

[IMPORTANT]
.Proxy Installation and Client Connections
====
During the installation of the proxy, clients will not be able to reach the {productname} server.
After a {susemgrproxy} system has been deleted from the systems list, all clients connected to this proxy will be (incorrectly) listed as `directly connected` to the {productname} server.
After the first successful operation on a client _such as execution of a remote command or installation of a package or patch_ this information will automatically be corrected.
This may take a few hours.
====



[[at.upgrade.a.susemgrproxy]]
=== Upgrading a {susemgrproxy} from 3 to 3.1

In most situations upgrading the proxy will be your preferred solution as this retains all cached packages.
Selecting this route saves time especially regarding proxies connected to {productname} server via low-bandwith links.
This upgrade is similar to a standard client migration.

[WARNING]
.Synchronizing Target Channels
====
Before successfully initializing the product migration, you first must make sure that the migration target channels are completely mirrored.
For the upgrade to {productname} 3.1 Proxy, at least the [systemitem]``SUSE Linux Enterprise Server 12 SP3`` base channel with the [systemitem]``SUSE Manager Proxy 3.1`` child channel for your architecture is required.
====

.Procedure: Migrating Proxy to 3.1
. Direct your browser to the {productname}{webui} where your proxy is registered, and login.
. On the menu:Systems[Systems > Proxy] page select your proxy client system from the table.
+

image::suma_proxy_old_details_page.png[]

. On the system's detail page select the menu:Software[] tab, then the menu:SP Migration[] tab.
+

image::suma_proxy_old_details_spmigration.png[]

. From this page you will see installed products listed on your proxy client, and the available target products.
Select the wanted menu:Target Products[] , which include [systemitem]``SUSE Linux Enterprise Server 12 SP3`` and [systemitem]``SUSE Manager Proxy 3.1`` .
+

image::suma_proxy_migration_target.png[]
+

Then confirm with menu:Select Channels[].
+

image::suma_proxy_migration_channels.png[]

. From the menu:Schedule Migration[] menu, and then btn:[Confirm] .

Check the menu:System Status[] on the system's details when the migration is done.

image::suma_proxy_migrated.png[]


[NOTE]
.Checking `refresh_pattern` in [path]``/etc/squid/squid.conf``
====
If you migrate from an early {susemgrproxy} 3.0 add the following `refresh_pattern` to [path]``/etc/squid/squid.conf``:

----
# salt minions get the repodata via a different URL
refresh_pattern /rhn/manager/download/.*/repodata/.*$ 0 1% 1440 ignore-no-cache reload-into-ims refresh-ims
----
====

Finally consider scheduling a reboot.



[[advanced.topics.proxy.migration]]
== Migrating {productname}  2.1 Proxy to Version 3.1

For the migration of {productname} 2.1 Proxies there are two possible approaches--this section documents both approaches:

* Existing {productname} proxies may be replaced by newly installed and reconfigured proxies, see <<advanced.topics.proxy.migration.replace>>.
This is the recommended method.
* Proxies may be auto-upgraded to version 3.1 by means of {yast} auto-installation, see <<advanced.topics.proxy.migration.upgrade>>.

[TIP]
.Order of Server and Proxy Migration
====
The recommended order for migrations is to first migrate the server and then the proxies.
A {productname} 2.1 Proxy works correctly with {productname} 3.1.
====



[[advanced.topics.proxy.migration.replace]]
=== Replacing a {susemgrproxy}

A {susemgrproxy} is `dumb` in the sense that it does not contain any information about the clients which are connected to it.
A {susemgrproxy} can therefore be replaced by a new one.
The replacement proxy must have the same name and IP address as its predecessor.

In order to replace a {susemgrproxy} and keeping the clients registered to the proxy leave the old proxy in {productname}.
Create a reactivation key for this system and then register the new proxy using the reactivation key.
If you do not use the reactivation key, you will need to re-registered all the clients against the new proxy.
[[proc.advanced.topics.proxy.migration21.replace]]
.Procedure: Replacing a {susemgrproxy}and Keeping the ClientsRegistered
. Before starting the actual migration procedure, save the important data from the old proxy.
Copy the data to a central place that also the new server can access:
** Copy the scripts that are still needed.
** Copy the activation keys from the existing server.
Of course, it is always better to re-create the keys.
. Shutdown the server.
. Install a new {productname} 3.1 Proxy, see <<at.manager.proxy.inst-and-clients>>.
+


[IMPORTANT]
.Proxy Installation and Client Connections
====
During the installation of the proxy, clients will not be able to reach the {productname} server.
After a {susemgrproxy} system has been deleted from the systems list, all clients connected to this proxy will be (incorrectly) listed as `directly connected` to the {productname} server.
After the first successful operation on a client _such as execution of a remote command or installation of a package or patch_ this information will automatically be corrected.
This may take a few hours.
====
+

. In the SUSE Manager {webui} select the newly installed {susemgrproxy} and delete it from the systems list.
[[step.at.proxy.migration.replace.react]]
. In the {webui} , create a reactivation key for the old proxy system: On the System Details of the old proxy click menu:Reactivation[].
Then click menu:Generate New Key[] , and remember it (write it on a piece of paper or copy it to the clipboard).
For more information about reactivation keys, see <<s5-sm-system-details-react>>.
. After the installation of the new proxy, perform the following actions (if needed):
** Copy the centrally saved data back to the new proxy system.
** Install any other needed software.
** If the proxy is also used for autoinstallation, do not forget to setup TFTP synchronization.



[[advanced.topics.proxy.migration.upgrade]]
=== Upgrading a {susemgrproxy} from 2.1 to 3.1

In other situations upgrading the proxy will be the preferred solution as it retains all cached packages.
This route saves time especially regarding proxies connected to a {productname} server via low-bandwith links.
This upgrade can be automated by using the {yast} auto-installation feature.

.Procedure: Upgrading {susemgrproxy}from 2.1 to 3.1
. Create an auto-installable distribution based on SLES 12 SP3.
{productname} 3.1 Proxy is an add-on for SLES 12 SP3.
Refer to the <<ref.webui.systems.autoinst>> on creating an auto-installable distribution.
. To start the auto-installation of a proxy, some additional packages must be installed that are only available in the {productname} Tools channel.
These tools were not available for proxies when in the past the system was shipped as an appliance.
To gain access to the required packages for use with proxies, the underlying SLES 11 SP3 channel ([systemitem]``SLES11-SP3-SUSE-Manager-Tools`` ) needs to be cloned and assigned to the to-be-upgraded proxies.
After these steps have been completed, create an auto-installation profile.

In the following example you will see an auto-install profile.
The label `Proxy31` is used both for the auto-installable distribution as well as for the auto-install profile.
Use the following auto-installation as template and create the auto-installation profile by uploading the edited file:

----
<?xml version="1.0"?>
<!DOCTYPE profile>
<profile xmlns="http://www.suse.com/1.0/yast2ns"
         xmlns:config="http://www.suse.com/1.0/configns">
  <general>
  $SNIPPET('spacewalk/sles_no_signature_checks')
    <mode>
      <confirm config:type="boolean">false</confirm>
    </mode>
  </general>
  <add-on>
    <add_on_products config:type="list">
      <listentry>
        <ask_on_error config:type="boolean">true</ask_on_error>
        <media_url>http://$redhat_management_server/ks/dist/child/sles12-sp3-updates-x86_64/Proxy31</media_url>
        <name>SLES12 SP3 Updates</name>
        <product>SLES12-SP3</product>
        <product_dir>/</product_dir>
      </listentry>
      <listentry>
        <ask_on_error config:type="boolean">true</ask_on_error>
        <media_url>http://$redhat_management_server/ks/dist/child/sle-manager-tools12-pool-x86_64-sp3/Proxy31</media_url>
        <name>SLE12 Manager Tools Pool</name>
        <product>SLES12</product>
        <product_dir>/</product_dir>
      </listentry>
      <listentry>
        <ask_on_error config:type="boolean">true</ask_on_error>
        <media_url>http://$redhat_management_server/ks/dist/child/sle-manager-tools12-updates-x86_64-sp3/Proxy31</media_url>
        <name>SLE12 Manager Tools Updates</name>
        <product>SLES12</product>
        <product_dir>/</product_dir>
      </listentry>
      <listentry>
        <ask_on_error config:type="boolean">true</ask_on_error>
        <media_url>http://$redhat_management_server/ks/dist/child/suse-manager-proxy-3.1-pool-x86_64/Proxy31</media_url>
        <name>SLE12 Proxy 3.1 Pool</name>
        <product>SLES12</product>
        <product_dir>/</product_dir>
      </listentry>
      <listentry>
        <ask_on_error config:type="boolean">true</ask_on_error>
        <media_url>http://$redhat_management_server/ks/dist/child/suse-manager-proxy-3.1-updates-x86_64/Proxy31</media_url>
        <name>SLE12 Proxy 3.1 Update</name>
        <product>SLES12</product>
        <product_dir>/</product_dir>
      </listentry>
    </add_on_products>
  </add-on>
  <upgrade>
    <only_installed_packages config:type="boolean">false</only_installed_packages>
    <stop_on_solver_conflict config:type="boolean">true</stop_on_solver_conflict>
  </upgrade>
  <backup>
    <sysconfig config:type="boolean">true</sysconfig>
    <modified config:type="boolean">true</modified>
    <remove_old config:type="boolean">false</remove_old>
  </backup>
  <networking>
    <keep_install_network config:type="boolean">true</keep_install_network>
    <start_immediately config:type="boolean">true</start_immediately>
  </networking>
  <scripts>
    <pre-scripts config:type="list">
      <script>
        <filename>remove_initrd_koan.sh</filename>
        <source>

        mount /dev/sda1 /mnt
        rm -f /mnt/initrd_koan
        umount /mnt

        </source>
      </script>
    </pre-scripts>
    <chroot-scripts config:type="list">
      <script>
        <filename>migration_fix_script.sh</filename>
        <chrooted config:type="boolean">true</chrooted>
        <source><![CDATA[ ln -sf /usr/share/rhn/RHN-ORG-TRUSTED-SSL-CERT /etc/pki/trust/anchors/
/usr/sbin/update-ca-certificates ]]>
</source>
      </script>
    </chroot-scripts>
    <init-scripts config:type="list">
      <script>
        <filename>sles_register.sh</filename>
        <source>

         $SNIPPET('spacewalk/sles_register')
         chmod 640 /etc/sysconfig/rhn/systemid
         chown root:www /etc/sysconfig/rhn/systemid
         systemctl enable squid
         systemctl start squid

        </source>
      </script>
    </init-scripts>
  </scripts>
</profile>
----

Ensure all channels referenced in this file are available and fully synced.
Replace the label `Proxy31` with the correct reference chosen for your auto-installation profile.
It is recommended to create a new activation key, for example: `1-sles12sp3` which has the relevant channels assigned; later this key will be used to subscribe the upgraded proxy with the correct channels.
The following base channel should be assigned:

----
SLES12-SP3-Pool
----

Also include the following child channels:

----
SLE-Manager-Tools12-Pool
SLE-Manager-Tools12-Updates
SLES12-SP3-Updates
SUSE-Manager-Proxy-3.1-Pool
SUSE-Manager-Proxy-3.1-Updates
----

In `Kernel Options` enter the following value:

----
autoupgrade=1 Y2DEBUG=1
----

The debug setting is not required but can help investigate problems in case something goes wrong; the [parameter]``autoupgrade`` parameter is vital! Do not remove it.

Save your changes then click on "Variables" and enter the following value:

----
registration_key=1-sles12sp3
----

Specify the name of the key which has all respective channels assigned to it.
The auto-install file contains a script named [command]``remove_initrd_koan.sh``.
In this script you should specify the device name of your [path]``/boot`` partition.

[NOTE]
.remove_initrd_koan.sh
====
The purpose of this script is to act as a workaround for the following problem: During installation the initrd of the installation media (SLES12SP3) is in use.
This initrd is rather large (around 50 MB), so there is not enough space left when the new kernel is being installed.
Therefore this script deletes the initial ramdisk file once it has been booted.
The partition of your boot partition might differ, so it should be explicitly specified in the autoinstall file.
====

During auto-installation this script attempts to delete the initial ramdisk file once it has booted.
Your boot partition may differ, so ensure it is explicitly specified within the auto-install file.

If this step is bypassed or mixed up (for example: specifying a wrong value) it's fine.
During installation of the new kernel, {yast} will detect that there is not enough space available and will stop.
You may switch to another console (there is a shell running on virtual console 2) and reclaim some disk space by issuing the command:

----
rm /mnt/boot/initrd_koan
----

When you have completed this step, switch back to the console where {yast} is running (console 7) and click menu:Retry[].
Installation of the kernel will continue and succeed.
The system will reboot, a few automated init scripts will run and the proxy will be upgraded to the {productname} 3.1 based on SLES12SP3 and will be fully functional.
